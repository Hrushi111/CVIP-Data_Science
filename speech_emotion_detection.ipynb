{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8/lvtqVWRrG1ZaF2T0fcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hrushi111/CVIP-Data_Science/blob/main/speech_emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjFsleYqnI5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e069f7bb-d37b-4522-94d1-a82384278632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.34.0 (from tensorflow-io)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.33.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.33.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.33.0\n",
            "Successfully installed tensorflow-io-0.34.0 tensorflow-io-gcs-filesystem-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow-io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from scipy.io import wavfile\n",
        "import os.path\n",
        "import IPython.display\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "import warnings\n"
      ],
      "metadata": {
        "id": "LT0ZQ1KboAqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = Path('../input/speech-emotion-recognition-en/Crema')"
      ],
      "metadata": {
        "id": "KHDWiXPcoAto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = list(image_dir.glob(r'**/*.wav'))"
      ],
      "metadata": {
        "id": "Kyr3Onv6oAxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(map(lambda x: os.path.split(x)[1].split('_')[2], filepaths))"
      ],
      "metadata": {
        "id": "nljmcH-0oA0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(labels)"
      ],
      "metadata": {
        "id": "FnFJ1v7GoA3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0ce1b8-1f03-4d17-a35f-7dcf697a887c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "audio_df = pd.concat([filepaths, labels], axis=1)\n",
        "audio_df"
      ],
      "metadata": {
        "id": "a9nEhazeoA6Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "71208e1e-1131-4ff8-fd5a-4d6fbcff0fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-74c8d0bcace3>:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
            "<ipython-input-7-74c8d0bcace3>:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  labels = pd.Series(labels, name='Label')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Filepath, Label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8dd9c126-7275-4f85-9819-d11f585e9e49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filepath</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dd9c126-7275-4f85-9819-d11f585e9e49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8dd9c126-7275-4f85-9819-d11f585e9e49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8dd9c126-7275-4f85-9819-d11f585e9e49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(12,8)})\n",
        "sns.set_style('darkgrid')\n",
        "sns.histplot(labels, color='#4FAEB0')"
      ],
      "metadata": {
        "id": "1a4htWxnoA9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_arrays = []\n",
        "\n",
        "for i in audio_df['Filepath']:\n",
        "    x, sr = librosa.load(i, sr=44100)\n",
        "    audio_arrays.append(x)\n",
        "\n",
        "audio_df['Arrays'] = audio_arrays"
      ],
      "metadata": {
        "id": "dknSdvOkoBAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_df"
      ],
      "metadata": {
        "id": "O6wTS5yroBDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angfile = audio_df[audio_df['Label'] == 'ANG']['Filepath']\n",
        "angarray = audio_df[audio_df['Label'] == 'ANG']['Arrays']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(angarray.iloc[0], color='#C00808')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Waveform')\n",
        "plt.show()\n",
        "\n",
        "IPython.display.Audio(angfile.iloc[0])"
      ],
      "metadata": {
        "id": "ExPCFgqGoBGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disfile = audio_df[audio_df['Label'] == 'DIS']['Filepath']\n",
        "disarray = audio_df[audio_df['Label'] == 'DIS']['Arrays']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveshow(disarray.iloc[0], color='#804E2D')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Waveform')\n",
        "plt.show()\n",
        "\n",
        "IPython.display.Audio(disfile.iloc[0])"
      ],
      "metadata": {
        "id": "75gn0Du_odha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feafile = audio_df[audio_df['Label'] == 'FEA']['Filepath']\n",
        "feaarray = audio_df[audio_df['Label'] == 'FEA']['Arrays']\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(feaarray.iloc[0], color='#7D55AA')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.title('Waveform')\n",
        "plt.show()\n",
        "\n",
        "IPython.display.Audio(feafile.iloc[0])"
      ],
      "metadata": {
        "id": "XBvdg3Hlodkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuarray = audio_df[audio_df['Label'] == 'NEU']['Arrays']\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(neuarray.iloc[0], color='#4CB847')\n",
        "plt.title('Waveplot')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3tVEasZwodnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sadarray = audio_df[audio_df['Label'] == 'SAD']['Arrays']\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(sadarray.iloc[0], color='#478FB8')\n",
        "plt.title('Waveplot')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R_ARhBiAodqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
      ],
      "metadata": {
        "id": "EFdM4QdvodtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(data):\n",
        "    # Zero Crossing Rate\n",
        "    result = np.array([])\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result = np.hstack((result, zcr))\n",
        "\n",
        "    # Chroma_stft\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr, n_fft=200).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft))\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_fft=200).T, axis=0)\n",
        "    result = np.hstack((result, mfcc))\n",
        "\n",
        "    # MelSpectogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sr, n_fft=200).T, axis=0)\n",
        "    result = np.hstack((result, mel))\n",
        "\n",
        "    # Tonnetz\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=data, sr=sr).T, axis=0)\n",
        "    result = np.hstack((result, tonnetz))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Trw0OT27oBKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(data):\n",
        "    result = []\n",
        "\n",
        "    # without augmentation\n",
        "    res1 = extract_features(data)\n",
        "    result.append(res1)\n",
        "\n",
        "    # with noise\n",
        "    noise_data = noise(data)\n",
        "    res2 = extract_features(noise_data)\n",
        "    result.append(res2)\n",
        "\n",
        "    # with stretching and pitching\n",
        "    new_data = stretch(data)\n",
        "    data_stretch_pitch = pitch(new_data, sr)\n",
        "    res3 = extract_features(data_stretch_pitch)\n",
        "    result.append(res3)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "JiTqv7QmoyDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)"
      ],
      "metadata": {
        "id": "gq2NkZ8woyGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}